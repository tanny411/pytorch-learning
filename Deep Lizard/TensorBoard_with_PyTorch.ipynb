{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorBoard with PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ZLWTJOHz65Cn",
        "bApPHCABAEWP",
        "19jsdoGAACWO",
        "KNuiTTRzwKki"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-J7QKmLaW5z",
        "colab_type": "text"
      },
      "source": [
        "https://www.youtube.com/watch?v=pSexXMdruFM&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHOt15tV1zwd",
        "colab_type": "text"
      },
      "source": [
        "- Tensorboard is Tensorflows machine larning toolkit.\n",
        "- It is a frotend web interface.\n",
        "- It reads from a file, and we can do that(writing) using pytorch summary writer.\n",
        "- It allows us to \n",
        "  - track and visualize our metrics, like our loss and accuracy\n",
        "  - histograms of weights and biases etc\n",
        "  - visualize our networks graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOKbnt1mZCMx",
        "colab_type": "text"
      },
      "source": [
        "### Normal way in command line:\n",
        "- !tensorboard --version\n",
        "- tensorboard --logdir=runs\n",
        "- this gives a localhost, where tensorboard will be running\n",
        "- `runs` is a folder in the current directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuYZVAjvarui",
        "colab_type": "text"
      },
      "source": [
        "### Other way(colab):\n",
        "https://medium.com/p/16b4bb9812a6/responses/show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znOaPcBq1s5x",
        "colab_type": "code",
        "outputId": "61243999-96d5-43e2-a42a-b3423f71088e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCGse_yh2h3U",
        "colab_type": "code",
        "outputId": "fd86c320-e4e9-47ec-fc04-1d7c4064b331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab\n",
        "tbc=TensorBoardColab(graph_path='./runs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://445fca16.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHC8X6s8dakf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "??TensorBoardColab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BYAmxvPajA8",
        "colab_type": "text"
      },
      "source": [
        "## The Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9L0LJnvZjWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "torch.set_printoptions(linewidth=120)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzR3koeSb3W1",
        "colab_type": "code",
        "outputId": "54545380-e129-4289-b772-381dafa6ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n",
            "0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spa6y_VLa2V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_correct(preds,labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILQVMsi1a2cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6 , out_channels=12 , kernel_size=5)\n",
        "        #we increase the number of output channels\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=12*4*4,out_features=120)\n",
        "        ## number of output channels * h * w of output channel\n",
        "        ## \n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
        "        self.out = nn.Linear(in_features=60,out_features=10)\n",
        "        # we descrease the number of nodes per layer\n",
        "    \n",
        "    def forward(self, t):\n",
        "        ## Convolution layers (with relu and maxpool)\n",
        "        t=F.max_pool2d(F.relu(self.conv1(t)),kernel_size=2,stride=2)\n",
        "        t=F.max_pool2d(F.relu(self.conv2(t)),kernel_size=2,stride=2)\n",
        "\n",
        "        ## Flatten\n",
        "        t=t.reshape(-1,12*4*4)\n",
        "\n",
        "        ## Linear layers\n",
        "        t=F.relu(self.fc1(t))\n",
        "        t=F.relu(self.fc2(t))\n",
        "\n",
        "        ## Output Layer\n",
        "        t=self.out(t)\n",
        "        # t=F.softmax(t,dim=1)\n",
        "        #dont have to mention softmax, cuz categorical crossentropy \n",
        "        #select korlei eita selecet hoye jay\n",
        "\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU5DTCxqa2eA",
        "colab_type": "code",
        "outputId": "a892f2e3-89df-4f8d-88ae-94415bbf1a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root='data/FashionMNIST',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "train_loader=torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True)\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root='data/FashionMNIST',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "test_loader=torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:04, 5643945.21it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 36165.72it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:02, 1694880.52it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 15392.92it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4XGRRYck-H",
        "colab_type": "text"
      },
      "source": [
        "## Starting with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdr5Sm5ucrbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb = SummaryWriter()\n",
        "\n",
        "network = Network()\n",
        "images,labels = next(iter(train_loader))\n",
        "grid=torchvision.utils.make_grid(images)\n",
        "\n",
        "tb.add_image('images',grid)\n",
        "tb.add_graph(network, images)\n",
        "tb.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqxqWYMccpcc",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_0XNJoC0vD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(batch_size,lr,shuffle,comment):\n",
        "  network = Network()\n",
        "  train_loader=torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=shuffle)\n",
        "  test_loader=torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "  num_epochs = 1\n",
        "\n",
        "  optimizer = optim.Adam(network.parameters(), lr=lr)\n",
        "\n",
        "  images,labels = next(iter(train_loader))\n",
        "  grid=torchvision.utils.make_grid(images)\n",
        "\n",
        "  ##summary writer will append the comment to the name of the run\n",
        "  ##so we will be able to recgnize it in tensorboard\n",
        "  \n",
        "  #comment=f' batch_size={batch_size} lr={lr}' \n",
        "  ## Now RunBuilder can handle arbitrary number of parameters\n",
        "  \n",
        "  tb = SummaryWriter(comment=comment)\n",
        "  tb.add_image('images',grid)\n",
        "  tb.add_graph(network, images)\n",
        "\n",
        "  network = network.to('cuda')\n",
        "\n",
        "  count = 0\n",
        "  iteration_list = []\n",
        "\n",
        "  train_loss_list = []\n",
        "  valid_loss_list = []\n",
        "  train_accuracy_list = []\n",
        "  valid_accuracy_list = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      total_train_loss = 0\n",
        "      total_train_correct = 0\n",
        "      total_train = 0\n",
        "\n",
        "      for i, data in enumerate(train_loader):\n",
        "\n",
        "          network.train()\n",
        "\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to('cuda')\n",
        "          labels = labels.to('cuda')\n",
        "\n",
        "          outputs = network(inputs) # Forward propagation\n",
        "          loss = F.cross_entropy(outputs, labels) # Calculate softmax and cross entropy loss\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()# Calculating gradients\n",
        "          optimizer.step()# Update parameters\n",
        "          \n",
        "          count += 1\n",
        "          total_train_loss += loss.item()*len(labels)\n",
        "          trloss=loss.item()\n",
        "          total_train_correct += get_num_correct(outputs,labels)\n",
        "          total_train += len(labels)\n",
        "\n",
        "          # TEST LOSS and ACCURACY\n",
        "          if count%50 == 0:\n",
        "              with torch.no_grad():\n",
        "\n",
        "                  network.eval() #for dropout, batchnorm type things\n",
        "\n",
        "                  total_valid_correct = 0\n",
        "                  total_valid = 0\n",
        "                  total_valid_loss = 0\n",
        "\n",
        "                  for data in test_loader:\n",
        "\n",
        "                      images, labels = data\n",
        "                      images = images.to('cuda')\n",
        "                      labels = labels.to('cuda')\n",
        "\n",
        "                      outputs = network(images)\n",
        "                      loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "                      total_valid_loss += loss.item()*len(labels)\n",
        "                      vlloss=loss.item()\n",
        "                      total_valid += len(labels)\n",
        "                      total_valid_correct += get_num_correct(outputs, labels)\n",
        "\n",
        "              valid_accuracy = 100 * total_valid_correct / float(total_valid)\n",
        "              train_accuracy = 100 * total_train_correct / float(total_train)\n",
        "\n",
        "              train_loss_list.append(total_train_loss/float(total_train))\n",
        "              valid_loss_list.append(total_valid_loss/float(total_valid))\n",
        "              valid_accuracy_list.append(valid_accuracy)\n",
        "              train_accuracy_list.append(train_accuracy)\n",
        "              iteration_list.append(count)\n",
        "\n",
        "              if count%200 == 0:\n",
        "                  print('Iteration/Epoch: {}/{}  Train_Loss: {:.4f} Train_Acc: {:.4f}% Test_Loss: {:.4f}  Test_Acc: {:.4f}%'\n",
        "                        .format(i,epoch+1,train_loss_list[-1],train_accuracy_list[-1],valid_loss_list[-1],valid_accuracy_list[-1]))\n",
        "      \n",
        "      tb.add_scalar('Train Loss', total_train_loss, epoch)\n",
        "      tb.add_scalar('Valid Loss', total_valid_loss, epoch)\n",
        "      tb.add_scalar('Train Acc', train_accuracy_list[-1], epoch)\n",
        "      tb.add_scalar('Valid Acc', valid_accuracy_list[-1], epoch)\n",
        "\n",
        "      ##passing a set of values, to create a histogram\n",
        "      for name, weight in network.named_parameters():\n",
        "        tb.add_histogram(name,weight,epoch)\n",
        "        tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
        "\n",
        "  tb.close()\n",
        "  print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2ViPFI56VKR",
        "colab_type": "text"
      },
      "source": [
        "**The main power of tensorboard comes when experimenting with multiple runs, and we can compare all those runs side by side. Suppose hyper parameter tuning, we can compare all accuracy and loss graphs with all those runs and find out the best model from these!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLWTJOHz65Cn",
        "colab_type": "text"
      },
      "source": [
        "## Hyper-parameter tuning and experimenting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bApPHCABAEWP",
        "colab_type": "text"
      },
      "source": [
        "### We can loop over parameter combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtHOE0s__pV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = [0.01,0.001]\n",
        "batch_size = [10, 100, 1000]\n",
        "shuffle = [True, False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofvtbFrd_pPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a in lr:\n",
        "  for b in batch-size:\n",
        "    train(a,b,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19jsdoGAACWO",
        "colab_type": "text"
      },
      "source": [
        "### There is a better way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhNCmQpuAOZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ym1nx9_AOWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = dict(\n",
        "    lr = [0.01,0.001],\n",
        "    batch_size = [10, 100, 1000],\n",
        "    shuffle = [True, False]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kRpzPgtAOTw",
        "colab_type": "code",
        "outputId": "7c52e871-3915-4593-9cfe-2f12ade24c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "param_values = [v for v in parameters.values()]\n",
        "param_values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQvFfuOmAfCl",
        "colab_type": "code",
        "outputId": "3ca6b733-52e6-4590-8c78-cd8893b6ae39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "for lr, batch, shuffle in product(*param_values):\n",
        "  print(lr, batch, shuffle)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01 10 True\n",
            "0.01 10 False\n",
            "0.01 100 True\n",
            "0.01 100 False\n",
            "0.01 1000 True\n",
            "0.01 1000 False\n",
            "0.001 10 True\n",
            "0.001 10 False\n",
            "0.001 100 True\n",
            "0.001 100 False\n",
            "0.001 1000 True\n",
            "0.001 1000 False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx42vaBM6S-J",
        "colab_type": "code",
        "outputId": "e9ecc127-6bb6-48b8-98e6-375493ab60ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for lr, batch, shuffle in product(*param_values):\n",
        "  comment=f' batch_size={batch_size} lr={lr}'\n",
        "  train(batch,lr,shuffle,comment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration/Epoch: 199/1  Train_Loss: 1.4644 Train_Acc: 44.8500% Test_Loss: 0.9728  Test_Acc: 61.6200%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 1.1825 Train_Acc: 55.2000% Test_Loss: 0.8515  Test_Acc: 67.5100%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 1.0539 Train_Acc: 59.8333% Test_Loss: 0.7483  Test_Acc: 71.2000%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.9876 Train_Acc: 62.2250% Test_Loss: 0.7216  Test_Acc: 71.8800%\n",
            "Iteration/Epoch: 999/1  Train_Loss: 0.9307 Train_Acc: 64.3000% Test_Loss: 0.7657  Test_Acc: 71.1400%\n",
            "Iteration/Epoch: 1199/1  Train_Loss: 0.8921 Train_Acc: 65.6500% Test_Loss: 0.7269  Test_Acc: 72.7000%\n",
            "Iteration/Epoch: 1399/1  Train_Loss: 0.8679 Train_Acc: 66.5571% Test_Loss: 0.6752  Test_Acc: 74.4200%\n",
            "Iteration/Epoch: 1599/1  Train_Loss: 0.8469 Train_Acc: 67.4500% Test_Loss: 0.7168  Test_Acc: 71.1500%\n",
            "Iteration/Epoch: 1799/1  Train_Loss: 0.8268 Train_Acc: 68.2444% Test_Loss: 0.6348  Test_Acc: 75.6300%\n",
            "Iteration/Epoch: 1999/1  Train_Loss: 0.8072 Train_Acc: 69.1000% Test_Loss: 0.6602  Test_Acc: 75.9200%\n",
            "Iteration/Epoch: 2199/1  Train_Loss: 0.7959 Train_Acc: 69.6682% Test_Loss: 0.6374  Test_Acc: 76.0800%\n",
            "Iteration/Epoch: 2399/1  Train_Loss: 0.7844 Train_Acc: 70.1875% Test_Loss: 0.7224  Test_Acc: 73.1900%\n",
            "Iteration/Epoch: 2599/1  Train_Loss: 0.7703 Train_Acc: 70.8462% Test_Loss: 0.6150  Test_Acc: 76.8700%\n",
            "Iteration/Epoch: 2799/1  Train_Loss: 0.7611 Train_Acc: 71.2464% Test_Loss: 0.6199  Test_Acc: 76.4300%\n",
            "Iteration/Epoch: 2999/1  Train_Loss: 0.7508 Train_Acc: 71.6733% Test_Loss: 0.6447  Test_Acc: 76.5100%\n",
            "Iteration/Epoch: 3199/1  Train_Loss: 0.7420 Train_Acc: 71.9781% Test_Loss: 0.6434  Test_Acc: 74.1700%\n",
            "Iteration/Epoch: 3399/1  Train_Loss: 0.7357 Train_Acc: 72.2382% Test_Loss: 0.7070  Test_Acc: 75.2900%\n",
            "Iteration/Epoch: 3599/1  Train_Loss: 0.7263 Train_Acc: 72.6111% Test_Loss: 0.6079  Test_Acc: 77.6400%\n",
            "Iteration/Epoch: 3799/1  Train_Loss: 0.7217 Train_Acc: 72.8737% Test_Loss: 0.6514  Test_Acc: 75.4100%\n",
            "Iteration/Epoch: 3999/1  Train_Loss: 0.7161 Train_Acc: 73.1325% Test_Loss: 0.6850  Test_Acc: 75.3900%\n",
            "Iteration/Epoch: 4199/1  Train_Loss: 0.7109 Train_Acc: 73.3405% Test_Loss: 0.5973  Test_Acc: 77.5600%\n",
            "Iteration/Epoch: 4399/1  Train_Loss: 0.7068 Train_Acc: 73.5432% Test_Loss: 0.6220  Test_Acc: 75.6800%\n",
            "Iteration/Epoch: 4599/1  Train_Loss: 0.7040 Train_Acc: 73.6609% Test_Loss: 0.6167  Test_Acc: 77.8600%\n",
            "Iteration/Epoch: 4799/1  Train_Loss: 0.6988 Train_Acc: 73.8917% Test_Loss: 0.6717  Test_Acc: 75.2400%\n",
            "Iteration/Epoch: 4999/1  Train_Loss: 0.6944 Train_Acc: 74.0940% Test_Loss: 0.6850  Test_Acc: 77.3200%\n",
            "Iteration/Epoch: 5199/1  Train_Loss: 0.6907 Train_Acc: 74.2885% Test_Loss: 0.6025  Test_Acc: 77.4200%\n",
            "Iteration/Epoch: 5399/1  Train_Loss: 0.6857 Train_Acc: 74.4444% Test_Loss: 0.6257  Test_Acc: 77.4900%\n",
            "Iteration/Epoch: 5599/1  Train_Loss: 0.6829 Train_Acc: 74.5482% Test_Loss: 0.6401  Test_Acc: 77.1300%\n",
            "Iteration/Epoch: 5799/1  Train_Loss: 0.6802 Train_Acc: 74.6397% Test_Loss: 0.7451  Test_Acc: 73.8700%\n",
            "Iteration/Epoch: 5999/1  Train_Loss: 0.6771 Train_Acc: 74.7850% Test_Loss: 0.5892  Test_Acc: 78.1800%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.5052 Train_Acc: 40.1500% Test_Loss: 1.0558  Test_Acc: 59.9100%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 1.2032 Train_Acc: 52.1750% Test_Loss: 0.8711  Test_Acc: 65.6500%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 1.0518 Train_Acc: 58.4500% Test_Loss: 0.7251  Test_Acc: 71.1300%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.9671 Train_Acc: 61.7000% Test_Loss: 0.8105  Test_Acc: 68.5700%\n",
            "Iteration/Epoch: 999/1  Train_Loss: 0.9148 Train_Acc: 63.9400% Test_Loss: 0.6260  Test_Acc: 76.0800%\n",
            "Iteration/Epoch: 1199/1  Train_Loss: 0.8724 Train_Acc: 65.8167% Test_Loss: 0.6249  Test_Acc: 76.7400%\n",
            "Iteration/Epoch: 1399/1  Train_Loss: 0.8450 Train_Acc: 67.1214% Test_Loss: 0.6233  Test_Acc: 76.9300%\n",
            "Iteration/Epoch: 1599/1  Train_Loss: 0.8162 Train_Acc: 68.3375% Test_Loss: 0.5762  Test_Acc: 79.1800%\n",
            "Iteration/Epoch: 1799/1  Train_Loss: 0.7977 Train_Acc: 69.1778% Test_Loss: 0.6164  Test_Acc: 72.8800%\n",
            "Iteration/Epoch: 1999/1  Train_Loss: 0.7801 Train_Acc: 69.8500% Test_Loss: 0.7291  Test_Acc: 73.3500%\n",
            "Iteration/Epoch: 2199/1  Train_Loss: 0.7645 Train_Acc: 70.4727% Test_Loss: 0.6096  Test_Acc: 77.4700%\n",
            "Iteration/Epoch: 2399/1  Train_Loss: 0.7516 Train_Acc: 71.1750% Test_Loss: 0.5664  Test_Acc: 78.5400%\n",
            "Iteration/Epoch: 2599/1  Train_Loss: 0.7381 Train_Acc: 71.8500% Test_Loss: 0.6014  Test_Acc: 79.4000%\n",
            "Iteration/Epoch: 2799/1  Train_Loss: 0.7276 Train_Acc: 72.3714% Test_Loss: 0.5748  Test_Acc: 79.0000%\n",
            "Iteration/Epoch: 2999/1  Train_Loss: 0.7192 Train_Acc: 72.8233% Test_Loss: 0.6007  Test_Acc: 78.3900%\n",
            "Iteration/Epoch: 3199/1  Train_Loss: 0.7077 Train_Acc: 73.3156% Test_Loss: 0.5430  Test_Acc: 80.8600%\n",
            "Iteration/Epoch: 3399/1  Train_Loss: 0.6975 Train_Acc: 73.7294% Test_Loss: 0.5089  Test_Acc: 81.8900%\n",
            "Iteration/Epoch: 3599/1  Train_Loss: 0.6874 Train_Acc: 74.1917% Test_Loss: 0.5339  Test_Acc: 80.6300%\n",
            "Iteration/Epoch: 3799/1  Train_Loss: 0.6799 Train_Acc: 74.5289% Test_Loss: 0.4935  Test_Acc: 81.8900%\n",
            "Iteration/Epoch: 3999/1  Train_Loss: 0.6713 Train_Acc: 74.8925% Test_Loss: 0.5195  Test_Acc: 81.8400%\n",
            "Iteration/Epoch: 4199/1  Train_Loss: 0.6649 Train_Acc: 75.2024% Test_Loss: 0.6057  Test_Acc: 78.4200%\n",
            "Iteration/Epoch: 4399/1  Train_Loss: 0.6596 Train_Acc: 75.4841% Test_Loss: 0.5619  Test_Acc: 80.0200%\n",
            "Iteration/Epoch: 4599/1  Train_Loss: 0.6548 Train_Acc: 75.6826% Test_Loss: 0.5754  Test_Acc: 79.1100%\n",
            "Iteration/Epoch: 4799/1  Train_Loss: 0.6499 Train_Acc: 75.8771% Test_Loss: 0.5559  Test_Acc: 81.0600%\n",
            "Iteration/Epoch: 4999/1  Train_Loss: 0.6454 Train_Acc: 76.0980% Test_Loss: 0.5556  Test_Acc: 80.4500%\n",
            "Iteration/Epoch: 5199/1  Train_Loss: 0.6423 Train_Acc: 76.2404% Test_Loss: 0.5418  Test_Acc: 80.4100%\n",
            "Iteration/Epoch: 5399/1  Train_Loss: 0.6393 Train_Acc: 76.3648% Test_Loss: 0.6088  Test_Acc: 78.7700%\n",
            "Iteration/Epoch: 5599/1  Train_Loss: 0.6364 Train_Acc: 76.4839% Test_Loss: 0.5208  Test_Acc: 80.5600%\n",
            "Iteration/Epoch: 5799/1  Train_Loss: 0.6322 Train_Acc: 76.6672% Test_Loss: 0.5451  Test_Acc: 80.3600%\n",
            "Iteration/Epoch: 5999/1  Train_Loss: 0.6282 Train_Acc: 76.8167% Test_Loss: 0.5158  Test_Acc: 81.1100%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 0.7785 Train_Acc: 69.4400% Test_Loss: 0.6225  Test_Acc: 75.8900%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.6316 Train_Acc: 75.7375% Test_Loss: 0.4638  Test_Acc: 83.1000%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.5644 Train_Acc: 78.5917% Test_Loss: 0.4382  Test_Acc: 84.3000%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 0.7746 Train_Acc: 70.3600% Test_Loss: 0.5521  Test_Acc: 78.4100%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.6374 Train_Acc: 75.7000% Test_Loss: 0.4854  Test_Acc: 80.5300%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.5729 Train_Acc: 78.2833% Test_Loss: 0.4586  Test_Acc: 82.9800%\n",
            "Finished Training\n",
            "Finished Training\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.3623 Train_Acc: 49.1500% Test_Loss: 0.8738  Test_Acc: 67.6400%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 1.0954 Train_Acc: 58.6250% Test_Loss: 0.8705  Test_Acc: 66.0100%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.9631 Train_Acc: 63.7167% Test_Loss: 0.7078  Test_Acc: 71.6600%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.8947 Train_Acc: 66.3000% Test_Loss: 0.6593  Test_Acc: 74.5200%\n",
            "Iteration/Epoch: 999/1  Train_Loss: 0.8434 Train_Acc: 67.9800% Test_Loss: 0.6291  Test_Acc: 76.1600%\n",
            "Iteration/Epoch: 1199/1  Train_Loss: 0.8045 Train_Acc: 69.2750% Test_Loss: 0.6088  Test_Acc: 76.4700%\n",
            "Iteration/Epoch: 1399/1  Train_Loss: 0.7756 Train_Acc: 70.4000% Test_Loss: 0.5955  Test_Acc: 77.0500%\n",
            "Iteration/Epoch: 1599/1  Train_Loss: 0.7489 Train_Acc: 71.2625% Test_Loss: 0.6449  Test_Acc: 75.1000%\n",
            "Iteration/Epoch: 1799/1  Train_Loss: 0.7301 Train_Acc: 71.9000% Test_Loss: 0.5649  Test_Acc: 78.0100%\n",
            "Iteration/Epoch: 1999/1  Train_Loss: 0.7110 Train_Acc: 72.6350% Test_Loss: 0.5665  Test_Acc: 78.2700%\n",
            "Iteration/Epoch: 2199/1  Train_Loss: 0.6950 Train_Acc: 73.2864% Test_Loss: 0.5723  Test_Acc: 78.9100%\n",
            "Iteration/Epoch: 2399/1  Train_Loss: 0.6801 Train_Acc: 73.8125% Test_Loss: 0.5180  Test_Acc: 80.8000%\n",
            "Iteration/Epoch: 2599/1  Train_Loss: 0.6674 Train_Acc: 74.2923% Test_Loss: 0.5276  Test_Acc: 79.4400%\n",
            "Iteration/Epoch: 2799/1  Train_Loss: 0.6565 Train_Acc: 74.8107% Test_Loss: 0.5266  Test_Acc: 80.1300%\n",
            "Iteration/Epoch: 2999/1  Train_Loss: 0.6465 Train_Acc: 75.2067% Test_Loss: 0.4903  Test_Acc: 81.1100%\n",
            "Iteration/Epoch: 3199/1  Train_Loss: 0.6366 Train_Acc: 75.5687% Test_Loss: 0.4863  Test_Acc: 81.6000%\n",
            "Iteration/Epoch: 3399/1  Train_Loss: 0.6269 Train_Acc: 75.9618% Test_Loss: 0.5212  Test_Acc: 80.7100%\n",
            "Iteration/Epoch: 3599/1  Train_Loss: 0.6171 Train_Acc: 76.3694% Test_Loss: 0.4849  Test_Acc: 82.4500%\n",
            "Iteration/Epoch: 3799/1  Train_Loss: 0.6080 Train_Acc: 76.7579% Test_Loss: 0.4710  Test_Acc: 82.1300%\n",
            "Iteration/Epoch: 3999/1  Train_Loss: 0.6022 Train_Acc: 76.9900% Test_Loss: 0.4708  Test_Acc: 82.0500%\n",
            "Iteration/Epoch: 4199/1  Train_Loss: 0.5951 Train_Acc: 77.3095% Test_Loss: 0.4615  Test_Acc: 82.6800%\n",
            "Iteration/Epoch: 4399/1  Train_Loss: 0.5880 Train_Acc: 77.5636% Test_Loss: 0.4515  Test_Acc: 83.2700%\n",
            "Iteration/Epoch: 4599/1  Train_Loss: 0.5818 Train_Acc: 77.8217% Test_Loss: 0.4542  Test_Acc: 83.4100%\n",
            "Iteration/Epoch: 4799/1  Train_Loss: 0.5761 Train_Acc: 78.0521% Test_Loss: 0.4478  Test_Acc: 83.7500%\n",
            "Iteration/Epoch: 4999/1  Train_Loss: 0.5702 Train_Acc: 78.3100% Test_Loss: 0.4330  Test_Acc: 83.9500%\n",
            "Iteration/Epoch: 5199/1  Train_Loss: 0.5640 Train_Acc: 78.5731% Test_Loss: 0.4510  Test_Acc: 83.1500%\n",
            "Iteration/Epoch: 5399/1  Train_Loss: 0.5585 Train_Acc: 78.8148% Test_Loss: 0.4424  Test_Acc: 83.8700%\n",
            "Iteration/Epoch: 5599/1  Train_Loss: 0.5529 Train_Acc: 79.0393% Test_Loss: 0.4179  Test_Acc: 84.8300%\n",
            "Iteration/Epoch: 5799/1  Train_Loss: 0.5464 Train_Acc: 79.3034% Test_Loss: 0.4429  Test_Acc: 84.4300%\n",
            "Iteration/Epoch: 5999/1  Train_Loss: 0.5418 Train_Acc: 79.4850% Test_Loss: 0.4304  Test_Acc: 84.3800%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.4322 Train_Acc: 46.5000% Test_Loss: 0.9648  Test_Acc: 63.8200%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 1.1371 Train_Acc: 57.3500% Test_Loss: 0.7568  Test_Acc: 72.6800%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.9911 Train_Acc: 62.8500% Test_Loss: 0.6902  Test_Acc: 74.7800%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.9121 Train_Acc: 65.3000% Test_Loss: 0.6527  Test_Acc: 73.9100%\n",
            "Iteration/Epoch: 999/1  Train_Loss: 0.8609 Train_Acc: 67.0100% Test_Loss: 0.6310  Test_Acc: 75.5800%\n",
            "Iteration/Epoch: 1199/1  Train_Loss: 0.8187 Train_Acc: 68.7000% Test_Loss: 0.6468  Test_Acc: 74.5700%\n",
            "Iteration/Epoch: 1399/1  Train_Loss: 0.7877 Train_Acc: 69.8500% Test_Loss: 0.6001  Test_Acc: 77.1600%\n",
            "Iteration/Epoch: 1599/1  Train_Loss: 0.7603 Train_Acc: 70.7938% Test_Loss: 0.5821  Test_Acc: 78.2200%\n",
            "Iteration/Epoch: 1799/1  Train_Loss: 0.7403 Train_Acc: 71.5389% Test_Loss: 0.5719  Test_Acc: 78.2800%\n",
            "Iteration/Epoch: 1999/1  Train_Loss: 0.7226 Train_Acc: 72.2000% Test_Loss: 0.5977  Test_Acc: 76.7200%\n",
            "Iteration/Epoch: 2199/1  Train_Loss: 0.7057 Train_Acc: 72.8955% Test_Loss: 0.5216  Test_Acc: 81.3100%\n",
            "Iteration/Epoch: 2399/1  Train_Loss: 0.6916 Train_Acc: 73.5625% Test_Loss: 0.5495  Test_Acc: 79.3100%\n",
            "Iteration/Epoch: 2599/1  Train_Loss: 0.6774 Train_Acc: 74.1000% Test_Loss: 0.4919  Test_Acc: 82.0500%\n",
            "Iteration/Epoch: 2799/1  Train_Loss: 0.6636 Train_Acc: 74.6786% Test_Loss: 0.5159  Test_Acc: 80.4900%\n",
            "Iteration/Epoch: 2999/1  Train_Loss: 0.6532 Train_Acc: 75.1233% Test_Loss: 0.4791  Test_Acc: 82.6600%\n",
            "Iteration/Epoch: 3199/1  Train_Loss: 0.6413 Train_Acc: 75.6250% Test_Loss: 0.4863  Test_Acc: 82.2900%\n",
            "Iteration/Epoch: 3399/1  Train_Loss: 0.6307 Train_Acc: 76.1029% Test_Loss: 0.4674  Test_Acc: 83.1900%\n",
            "Iteration/Epoch: 3599/1  Train_Loss: 0.6212 Train_Acc: 76.5806% Test_Loss: 0.5056  Test_Acc: 81.6200%\n",
            "Iteration/Epoch: 3799/1  Train_Loss: 0.6125 Train_Acc: 76.9368% Test_Loss: 0.4520  Test_Acc: 84.0000%\n",
            "Iteration/Epoch: 3999/1  Train_Loss: 0.6037 Train_Acc: 77.3600% Test_Loss: 0.4563  Test_Acc: 83.4600%\n",
            "Iteration/Epoch: 4199/1  Train_Loss: 0.5966 Train_Acc: 77.6476% Test_Loss: 0.4443  Test_Acc: 83.7500%\n",
            "Iteration/Epoch: 4399/1  Train_Loss: 0.5890 Train_Acc: 77.9727% Test_Loss: 0.4590  Test_Acc: 83.4700%\n",
            "Iteration/Epoch: 4599/1  Train_Loss: 0.5831 Train_Acc: 78.2217% Test_Loss: 0.4555  Test_Acc: 83.4300%\n",
            "Iteration/Epoch: 4799/1  Train_Loss: 0.5766 Train_Acc: 78.4250% Test_Loss: 0.4306  Test_Acc: 84.0500%\n",
            "Iteration/Epoch: 4999/1  Train_Loss: 0.5699 Train_Acc: 78.6920% Test_Loss: 0.4242  Test_Acc: 84.6100%\n",
            "Iteration/Epoch: 5199/1  Train_Loss: 0.5646 Train_Acc: 78.8923% Test_Loss: 0.4236  Test_Acc: 84.7200%\n",
            "Iteration/Epoch: 5399/1  Train_Loss: 0.5598 Train_Acc: 79.0926% Test_Loss: 0.4302  Test_Acc: 84.5600%\n",
            "Iteration/Epoch: 5599/1  Train_Loss: 0.5544 Train_Acc: 79.2857% Test_Loss: 0.4216  Test_Acc: 84.9100%\n",
            "Iteration/Epoch: 5799/1  Train_Loss: 0.5497 Train_Acc: 79.4793% Test_Loss: 0.4156  Test_Acc: 84.6100%\n",
            "Iteration/Epoch: 5999/1  Train_Loss: 0.5446 Train_Acc: 79.6583% Test_Loss: 0.4290  Test_Acc: 84.9000%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.0906 Train_Acc: 59.6500% Test_Loss: 0.7300  Test_Acc: 69.9200%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.8664 Train_Acc: 67.4225% Test_Loss: 0.6293  Test_Acc: 76.0700%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.7684 Train_Acc: 70.9333% Test_Loss: 0.5839  Test_Acc: 78.0700%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.0779 Train_Acc: 59.4600% Test_Loss: 0.7144  Test_Acc: 73.1200%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.8673 Train_Acc: 67.2525% Test_Loss: 0.6244  Test_Acc: 76.0800%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.7763 Train_Acc: 70.5833% Test_Loss: 0.5940  Test_Acc: 77.7800%\n",
            "Finished Training\n",
            "Finished Training\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuMHdGEZ-5sy",
        "colab_type": "code",
        "outputId": "99768c7d-e7c0-4562-82bb-813b30346d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "!ls runs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Aug26_17-43-15_95eab96116ed batch_size=10 lr=0.01'\n",
            "'Aug26_17-48-30_95eab96116ed batch_size=10 lr=0.01'\n",
            "'Aug26_17-53-38_95eab96116ed batch_size=100 lr=0.01'\n",
            "'Aug26_17-54-04_95eab96116ed batch_size=100 lr=0.01'\n",
            "'Aug26_17-54-31_95eab96116ed batch_size=1000 lr=0.01'\n",
            "'Aug26_17-54-41_95eab96116ed batch_size=1000 lr=0.01'\n",
            "'Aug26_17-54-52_95eab96116ed batch_size=10 lr=0.001'\n",
            "'Aug26_18-00-03_95eab96116ed batch_size=10 lr=0.001'\n",
            "'Aug26_18-05-14_95eab96116ed batch_size=100 lr=0.001'\n",
            "'Aug26_18-05-41_95eab96116ed batch_size=100 lr=0.001'\n",
            "'Aug26_18-06-07_95eab96116ed batch_size=1000 lr=0.001'\n",
            "'Aug26_18-06-18_95eab96116ed batch_size=1000 lr=0.001'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNuiTTRzwKki",
        "colab_type": "text"
      },
      "source": [
        "## Run Builder Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNpQHK8EwdUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BVMSSh9wX06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = OrderedDict(\n",
        "    lr = [0.01,0.001],\n",
        "    batch_size = [64, 128]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qLiUdpfwzt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Run = namedtuple('Run',params.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1zvlaOryMgy",
        "colab_type": "code",
        "outputId": "bfe9d565-28b3-4161-e953-3ea448b8cf94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "run = []\n",
        "for v in product(*params.values()):\n",
        "  run.append(Run(*v)) #take the tuple values as the arguments, not the tuple itself\n",
        "  \n",
        "run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Run(lr=0.01, batch_size=64),\n",
              " Run(lr=0.01, batch_size=128),\n",
              " Run(lr=0.001, batch_size=64),\n",
              " Run(lr=0.001, batch_size=128)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXhiON5Gymo4",
        "colab_type": "code",
        "outputId": "0a9c2a2e-af66-4103-f7ed-526810875240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "run[3].lr, run[1].batch_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.001, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaR0dV1SzY6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "    Run = namedtuple('Run',params.keys())\n",
        "    run = []\n",
        "    for v in product(*params.values()):\n",
        "      run.append(Run(*v))\n",
        "    return run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySyEniF4zyv6",
        "colab_type": "code",
        "outputId": "fa9d5107-276c-4918-c9ef-c2445626a727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "#### BEFORE ####\n",
        "# for lr, batch, shuffle in product(*param_values):\n",
        "#   train(batch,lr,shuffle)\n",
        "#### AFTER ####\n",
        "for run in RunBuilder.get_runs(params):\n",
        "  comment = f'-{run}'\n",
        "  train(run.batch_size,run.lr,True,comment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration/Epoch: 199/1  Train_Loss: 0.8366 Train_Acc: 68.2891% Test_Loss: 0.6665  Test_Acc: 75.0600%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.7003 Train_Acc: 73.6211% Test_Loss: 0.5222  Test_Acc: 80.7500%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.6329 Train_Acc: 76.1927% Test_Loss: 0.5206  Test_Acc: 80.4300%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.5877 Train_Acc: 77.9492% Test_Loss: 0.4409  Test_Acc: 83.7000%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 0.8338 Train_Acc: 67.4609% Test_Loss: 0.6110  Test_Acc: 76.3000%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.6855 Train_Acc: 73.6387% Test_Loss: 0.5014  Test_Acc: 81.2100%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.1056 Train_Acc: 58.7812% Test_Loss: 0.7720  Test_Acc: 69.8100%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.9049 Train_Acc: 66.0586% Test_Loss: 0.6580  Test_Acc: 74.7400%\n",
            "Iteration/Epoch: 599/1  Train_Loss: 0.8106 Train_Acc: 69.4115% Test_Loss: 0.5771  Test_Acc: 78.0800%\n",
            "Iteration/Epoch: 799/1  Train_Loss: 0.7472 Train_Acc: 71.7891% Test_Loss: 0.5670  Test_Acc: 78.5600%\n",
            "Finished Training\n",
            "Iteration/Epoch: 199/1  Train_Loss: 1.0849 Train_Acc: 60.1758% Test_Loss: 0.7390  Test_Acc: 70.3100%\n",
            "Iteration/Epoch: 399/1  Train_Loss: 0.8798 Train_Acc: 67.0703% Test_Loss: 0.6251  Test_Acc: 76.0400%\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_P1ccDm1Xrv",
        "colab_type": "text"
      },
      "source": [
        "## Training loop refactoring and simulataneous hyperparamater testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blmojW17_OY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "\n",
        "from itertools import product\n",
        "from collections import namedtuple\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdgdDCW4fQqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RunManager():\n",
        "  def __init__(self):\n",
        "\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_valid_loss = 0\n",
        "    self.epoch_valid_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    self.network = None\n",
        "    self.trainloader = None\n",
        "    self.testloader = None\n",
        "    self.tb = None\n",
        "  \n",
        "  def begin_run(self, run, network, trainloader, testloader):\n",
        "\n",
        "    self.run_start_time = time.time()\n",
        "\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "\n",
        "    self.network = network\n",
        "    self.trainloader = trainloader\n",
        "    self.testloader = testloader\n",
        "    self.tb = SummaryWriter(comment=f'-{run}')\n",
        "\n",
        "    images, labels = next(iter(self.trainloader))\n",
        "    images=images.to('cuda')\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "    self.tb.add_image('images', grid)\n",
        "    self.tb.add_graph(self.network, images)\n",
        "\n",
        "  def end_run(self):\n",
        "    self.tb.close()\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.epoch_start_time = time.time()\n",
        "\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_valid_loss = 0\n",
        "    self.epoch_valid_num_correct = 0\n",
        "\n",
        "  def end_epoch(self):\n",
        "\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    loss = self.epoch_loss / len(self.trainloader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.trainloader.dataset)\n",
        "\n",
        "    valid_loss = self.epoch_valid_loss / len(self.testloader.dataset)\n",
        "    valid_accuracy = self.epoch_valid_num_correct / len(self.testloader.dataset)\n",
        "\n",
        "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
        "\n",
        "    self.tb.add_scalar('Valid Loss', loss, self.epoch_count)\n",
        "    self.tb.add_scalar('Valid Accuracy', accuracy, self.epoch_count)\n",
        "\n",
        "    for name, param in self.network.named_parameters():\n",
        "      self.tb.add_histogram(name, param, self.epoch_count)\n",
        "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
        "\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results['loss'] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results['valid loss'] = valid_loss\n",
        "    results[\"valid accuracy\"] = valid_accuracy\n",
        "    results['epoch duration'] = epoch_duration\n",
        "    results['run duration'] = run_duration\n",
        "\n",
        "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
        "    self.run_data.append(results)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(df)\n",
        "\n",
        "  def track_loss(self, loss):\n",
        "    self.epoch_loss += loss.item() * self.trainloader.batch_size\n",
        "\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
        "\n",
        "  def track_valid_loss(self, loss):\n",
        "    self.epoch_valid_loss += loss.item() * self.testloader.batch_size\n",
        "\n",
        "  def track_valid_num_correct(self, preds, labels):\n",
        "    self.epoch_valid_num_correct += self._get_num_correct(preds, labels)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "  def save(self, fileName):\n",
        "    \n",
        "    pd.DataFrame.from_dict(\n",
        "        self.run_data, orient='columns'\n",
        "    ).to_csv(f'{fileName}.csv')\n",
        "\n",
        "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3dRkRMYeT0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "9489e568-de7b-4ed2-e1fe-d8e3bad0fe7d"
      },
      "source": [
        "params = OrderedDict(\n",
        "    lr = [.01]\n",
        "    ,batch_size = [1000, 2000]\n",
        "    ,shuffle = [True]\n",
        ")\n",
        "m = RunManager()\n",
        "for run in RunBuilder.get_runs(params):\n",
        "  \n",
        "  network = Network()\n",
        "  network = network.to('cuda')\n",
        "  \n",
        "  train_loader=torch.utils.data.DataLoader(train_set, batch_size=run.batch_size,shuffle=run.shuffle)\n",
        "  test_loader=torch.utils.data.DataLoader(test_set, batch_size=run.batch_size)\n",
        "  \n",
        "  optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
        "\n",
        "  m.begin_run(run,network,train_loader,test_loader)\n",
        "  for epoch in range(5):\n",
        "    m.begin_epoch()\n",
        "\n",
        "    ##training\n",
        "    network.train()\n",
        "    for data in train_loader:\n",
        "      inputs, labels = data[0].to('cuda'), data[1].to('cuda')\n",
        "      outputs = network(inputs)\n",
        "      loss = F.cross_entropy(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      m.track_loss(loss)\n",
        "      m.track_num_correct(outputs,labels)\n",
        "    \n",
        "    ## validation\n",
        "    with torch.no_grad():\n",
        "      network.eval()\n",
        "      for data in test_loader:\n",
        "        inputs, labels = data[0].to('cuda'), data[1].to('cuda')\n",
        "        outputs = network(inputs)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "        m.track_valid_loss(loss)\n",
        "        m.track_valid_num_correct(outputs,labels)\n",
        "\n",
        "    m.end_epoch()\n",
        "  m.end_run()\n",
        "m.save('results')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>valid loss</th>\n",
              "      <th>valid accuracy</th>\n",
              "      <th>epoch duration</th>\n",
              "      <th>run duration</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>shuffle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.962823</td>\n",
              "      <td>0.624650</td>\n",
              "      <td>0.619712</td>\n",
              "      <td>0.7521</td>\n",
              "      <td>9.474450</td>\n",
              "      <td>10.087543</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.546383</td>\n",
              "      <td>0.784817</td>\n",
              "      <td>0.518220</td>\n",
              "      <td>0.8043</td>\n",
              "      <td>9.602154</td>\n",
              "      <td>19.853848</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.447019</td>\n",
              "      <td>0.833367</td>\n",
              "      <td>0.439939</td>\n",
              "      <td>0.8372</td>\n",
              "      <td>9.659519</td>\n",
              "      <td>29.650491</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.406291</td>\n",
              "      <td>0.850567</td>\n",
              "      <td>0.396699</td>\n",
              "      <td>0.8529</td>\n",
              "      <td>9.612568</td>\n",
              "      <td>39.406079</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.364422</td>\n",
              "      <td>0.865817</td>\n",
              "      <td>0.381028</td>\n",
              "      <td>0.8649</td>\n",
              "      <td>9.595242</td>\n",
              "      <td>49.148579</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.260493</td>\n",
              "      <td>0.524867</td>\n",
              "      <td>0.732135</td>\n",
              "      <td>0.7315</td>\n",
              "      <td>9.817601</td>\n",
              "      <td>10.743270</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.637478</td>\n",
              "      <td>0.750933</td>\n",
              "      <td>0.572166</td>\n",
              "      <td>0.7745</td>\n",
              "      <td>9.703493</td>\n",
              "      <td>20.589442</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.522696</td>\n",
              "      <td>0.798367</td>\n",
              "      <td>0.512680</td>\n",
              "      <td>0.8065</td>\n",
              "      <td>9.639640</td>\n",
              "      <td>30.369701</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.465717</td>\n",
              "      <td>0.827367</td>\n",
              "      <td>0.454987</td>\n",
              "      <td>0.8349</td>\n",
              "      <td>9.656057</td>\n",
              "      <td>40.173634</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.419567</td>\n",
              "      <td>0.847950</td>\n",
              "      <td>0.421784</td>\n",
              "      <td>0.8468</td>\n",
              "      <td>9.653873</td>\n",
              "      <td>49.971560</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   run  epoch      loss  accuracy  ...  run duration    lr  batch_size  shuffle\n",
              "0    1      1  0.962823  0.624650  ...     10.087543  0.01        1000     True\n",
              "1    1      2  0.546383  0.784817  ...     19.853848  0.01        1000     True\n",
              "2    1      3  0.447019  0.833367  ...     29.650491  0.01        1000     True\n",
              "3    1      4  0.406291  0.850567  ...     39.406079  0.01        1000     True\n",
              "4    1      5  0.364422  0.865817  ...     49.148579  0.01        1000     True\n",
              "5    2      1  1.260493  0.524867  ...     10.743270  0.01        2000     True\n",
              "6    2      2  0.637478  0.750933  ...     20.589442  0.01        2000     True\n",
              "7    2      3  0.522696  0.798367  ...     30.369701  0.01        2000     True\n",
              "8    2      4  0.465717  0.827367  ...     40.173634  0.01        2000     True\n",
              "9    2      5  0.419567  0.847950  ...     49.971560  0.01        2000     True\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIj0ao-ZtsWH",
        "colab_type": "text"
      },
      "source": [
        "#### Code smells in this version of refactoring:\n",
        "1. many variables with the name epoch. should be extracted into a separate class\n",
        "2. some to('cuda') here and there. this needs to be specified in one place\n",
        "3. validation and training loss,acc calculation has different functions. needs to be combined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpFG2voVsfZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}